\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{3}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:literaturereview}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Natural Language Processing}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Tokenization}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Evolution of Language Models}{4}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Timeline of Model evolution in NLP.\relax }}{4}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:timeline}{{2.1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Bag of Words}{4}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Example of scoring methods\relax }}{5}{}\protected@file@percent }
\newlabel{tab:scoring}{{2.1}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Term Frequency - Inverse Document Frequency}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Word Embeddings}{6}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces One Hot Encoding Example\relax }}{6}{}\protected@file@percent }
\newlabel{tab:onehot}{{2.2}{6}}
\@writefile{toc}{\contentsline {subsubsection}{Word2Vec Architecture}{6}{}\protected@file@percent }
\citation{Devlin}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Transformer}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Transformer Architecture\relax }}{7}{}\protected@file@percent }
\newlabel{fig:transformer}{{2.2}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.7}BERT}{7}{}\protected@file@percent }
\newlabel{bert}{{2.1.7}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Embeddings of Text Input with BERT.\relax }}{8}{}\protected@file@percent }
\newlabel{fig:bert_tokenizing}{{2.3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Pre-Training and Fine-Tuning Process of BERT\relax }}{8}{}\protected@file@percent }
\newlabel{fig:bert_tokenizing}{{2.4}{8}}
\citation{Beltagy}
\@writefile{toc}{\contentsline {subsubsection}{Difference from BERT and word2Vec}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.8}From BERT to SciBERT}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Masked Language Modelling}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Named Entity Recognition}{9}{}\protected@file@percent }
\@setckpt{3_literaturereview/literaturereview}{
\setcounter{page}{10}
\setcounter{equation}{3}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{2}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{float@type}{16}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{FancyVerbLine}{0}
\setcounter{linenumber}{1}
\setcounter{LN@truepage}{19}
\setcounter{FV@TrueTabGroupLevel}{0}
\setcounter{FV@TrueTabCounter}{0}
\setcounter{FV@HighlightLinesStart}{0}
\setcounter{FV@HighlightLinesStop}{0}
\setcounter{FancyVerbLineBreakLast}{0}
\setcounter{minted@FancyVerbLineTemp}{0}
\setcounter{minted@pygmentizecounter}{0}
\setcounter{listing}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{lstlisting}{0}
}
