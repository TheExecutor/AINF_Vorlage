\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Review}{7}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:literaturereview}{{2}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Natural Language Processing}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Text Representation}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}One-Hot Encoding}{8}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces One Hot Encoding Example\relax }}{8}{}\protected@file@percent }
\newlabel{tab:onehot}{{2.1}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Term Frequency - Inverse Document Frequency}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Bag of Words}{9}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Example of scoring methods\relax }}{10}{}\protected@file@percent }
\newlabel{tab:scoring}{{2.2}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Word Embeddings}{10}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces One Hot Encoding Example\relax }}{10}{}\protected@file@percent }
\newlabel{tab:onehot}{{2.3}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Word2Vec Architecture}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Masked Language Modelling}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Transformer}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Transformer Architecture\relax }}{11}{}\protected@file@percent }
\newlabel{fig:transformer}{{2.1}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Evolution of Language Models}{11}{}\protected@file@percent }
\citation{Devlin}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Timeline of Model evolution in NLP.\relax }}{12}{}\protected@file@percent }
\newlabel{fig:timeline}{{2.2}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}BERT}{12}{}\protected@file@percent }
\newlabel{bert}{{2.3.3}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Embeddings of Text Input with BERT.\relax }}{13}{}\protected@file@percent }
\newlabel{fig:bert_tokenizing}{{2.3}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Pre-Training and Fine-Tuning Process of BERT\relax }}{13}{}\protected@file@percent }
\newlabel{fig:bert_tokenizing}{{2.4}{13}}
\@writefile{toc}{\contentsline {subsubsection}{Difference from BERT and word2Vec}{13}{}\protected@file@percent }
\@setckpt{3_literaturereview/literaturereview}{
\setcounter{page}{15}
\setcounter{equation}{3}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{3}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{float@type}{16}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{FancyVerbLine}{0}
\setcounter{linenumber}{1}
\setcounter{LN@truepage}{24}
\setcounter{FV@TrueTabGroupLevel}{0}
\setcounter{FV@TrueTabCounter}{0}
\setcounter{FV@HighlightLinesStart}{0}
\setcounter{FV@HighlightLinesStop}{0}
\setcounter{FancyVerbLineBreakLast}{0}
\setcounter{minted@FancyVerbLineTemp}{0}
\setcounter{minted@pygmentizecounter}{0}
\setcounter{listing}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{lstlisting}{0}
}
